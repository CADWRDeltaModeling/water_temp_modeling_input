{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9MMWJBdL5VdB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 719,
     "status": "ok",
     "timestamp": 1609660672028,
     "user": {
      "displayName": "H K",
      "photoUrl": "",
      "userId": "12235360574546678823"
     },
     "user_tz": 480
    },
    "id": "xqOH_OFukoW0",
    "outputId": "28f39f86-47df-40ae-9b8b-6676efb2b90b"
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Housekeeping\n",
    "###############################################################################\n",
    "dir_input = os.path.join(\"./inputs\")\n",
    "dir_metsim = os.path.join(\"./processing\")\n",
    "dir_out = dir_metsim\n",
    "\n",
    "if not os.path.exists(dir_out):\n",
    "  os.makedirs(dir_out)\n",
    "\n",
    "fname_obs = \"RelativeHumidityDataforBC.xlsx\"\n",
    "fname_model = \"Timeseries_step1_drybulb,raw_cloud,raw_relhum.csv\"\n",
    "\n",
    "dt0_obs = datetime(1973, 1, 1, 0, 0)\n",
    "dt1_obs = datetime(2015, 12, 31, 23, 0)\n",
    "\n",
    "dt0_model = datetime(1915, 1, 1, 0, 0)\n",
    "dt1_model = datetime(2015, 12, 31, 23, 0)\n",
    "\n",
    "mode_list = [\"Model\", \"Obs\"]\n",
    "\n",
    "# Print to csv\n",
    "icsv = 1\n",
    "\n",
    "# For plot\n",
    "dpif = 200\n",
    "num_bins = 200 #CDF bins\n",
    "\n",
    "# Outlier to be removed\n",
    "outlier_cut = 100\n",
    "print(\"Outlier_cut: \" + str(outlier_cut))\n",
    "\n",
    "bias_correction = \"Quantile_Mapping\"\n",
    "\n",
    "num_percentile = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "di7VqBMMrqsf"
   },
   "source": [
    "## Read input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mS7d5Iw1rfqu"
   },
   "outputs": [],
   "source": [
    "df_obs = pd.read_excel(os.path.join(dir_input, fname_obs))\n",
    "df_model = pd.read_csv(os.path.join(dir_metsim, fname_model),\n",
    "                       usecols=[\"Date\", \"Relative Humidity [%]\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "# Create index in correct format using pandas date_range\n",
    "##########################################################################\n",
    "\n",
    "# Observed\n",
    "dt0 = df_obs[\"Date\"].iloc[0]\n",
    "dt1 = df_obs[\"Date\"].iloc[-1]\n",
    "index = pd.date_range(dt0, dt1, freq = timedelta(hours = 1))\n",
    "df_obs = df_obs.set_index(index)\n",
    "df_obs = df_obs.drop(\"Date\", axis = 1)\n",
    "\n",
    "# Model\n",
    "dt0 = df_model[\"Date\"].iloc[0]\n",
    "dt1 = df_model[\"Date\"].iloc[-1]\n",
    "index = pd.date_range(dt0, dt1, freq = timedelta(hours = 1))\n",
    "df_model = df_model.set_index(index)\n",
    "df_model = df_model.drop(\"Date\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initial = pd.concat([df_model, df_obs], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nMEECKyrr2ke"
   },
   "source": [
    "## Clean up the input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "68r6eTOxsK8Q"
   },
   "outputs": [],
   "source": [
    "df_raw = df_initial.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28531,
     "status": "ok",
     "timestamp": 1609660699856,
     "user": {
      "displayName": "H K",
      "photoUrl": "",
      "userId": "12235360574546678823"
     },
     "user_tz": 480
    },
    "id": "E7ugZtENyrWt",
    "outputId": "169abc09-7784-40ad-8976-7714d9637b2b"
   },
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "# Replace column names for convenience\n",
    "##########################################################################\n",
    "print(df_raw.columns)\n",
    "df_raw = df_raw.rename(columns = {df_raw.columns[0]: mode_list[0],\n",
    "                                  df_raw.columns[1]: mode_list[1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S55i4zhYSw8S"
   },
   "source": [
    "# Generate Timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 59850,
     "status": "ok",
     "timestamp": 1609660731180,
     "user": {
      "displayName": "H K",
      "photoUrl": "",
      "userId": "12235360574546678823"
     },
     "user_tz": 480
    },
    "id": "7LKRhgPPTj4D",
    "outputId": "30579479-a508-4a02-8e05-497aea23cc7a"
   },
   "outputs": [],
   "source": [
    "dict_ts = {}\n",
    "for mode in mode_list:\n",
    "\n",
    "  dict_ts[mode] = {}\n",
    "  \n",
    "  print(\"Generating timeseries: \" + mode)\n",
    "\n",
    "  ##########################################################################\n",
    "  # Hourly data\n",
    "  ##########################################################################\n",
    "\n",
    "  #\n",
    "  # Remove outliers by replacing them with NaN\n",
    "  #\n",
    "\n",
    "  # Check max value\n",
    "  df_nonan = df_raw[~pd.isnull(df_raw[mode])]\n",
    "  print(\"Max: \" + str(max(df_nonan[mode])))\n",
    "\n",
    "  # Identify outliers\n",
    "  df_remove = df_raw[df_raw >= outlier_cut]\n",
    "\n",
    "  # Extract non-NaN values\n",
    "  df_remove = df_remove[~pd.isnull(df_remove[mode])]\n",
    "\n",
    "  # Extract unique values\n",
    "  list_remove = df_remove[mode].tolist()\n",
    "  set_remove = set(list_remove)\n",
    "  list_remove = list(set_remove)\n",
    "\n",
    "  # Replace them to NaN\n",
    "  if (len(list_remove) > 0):\n",
    "    print(\"Outliers:\", list_remove)\n",
    "    df_raw = df_raw.replace(list_remove, np.NaN)\n",
    "  else:\n",
    "    pass\n",
    "\n",
    "  df_hourly = df_raw[mode]\n",
    "\n",
    "  ############################################################################\n",
    "  # Save timeseries into dictionary for later use\n",
    "  ############################################################################\n",
    "  dict_ts[mode] = {\"Hourly\": df_hourly}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IB11QdJrNpBA"
   },
   "source": [
    "# Bias Correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZpzTMdMqVHnw"
   },
   "source": [
    "## Quantile Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2451,
     "status": "ok",
     "timestamp": 1609661716983,
     "user": {
      "displayName": "H K",
      "photoUrl": "",
      "userId": "12235360574546678823"
     },
     "user_tz": 480
    },
    "id": "ZyXiRfmmVKPJ",
    "outputId": "2ae4aadb-e9f1-4461-eb4d-11d0f6439fb7"
   },
   "outputs": [],
   "source": [
    "col0 = \"Model (Adj)\"\n",
    "\n",
    "dict_ts_adj = {}\n",
    "\n",
    "print(\"Generating timeseries for adjusted model output\")\n",
    "\n",
    "dict_ts_adj = {}\n",
    "############################################################################\n",
    "# Hourly timeseries\n",
    "############################################################################\n",
    "df_tmp = dict_ts[\"Obs\"][\"Hourly\"][dt0_obs:dt1_obs]\n",
    "df_tmp = df_tmp.replace(0, np.nan)\n",
    "df_obs_hourly = df_tmp.dropna()\n",
    "\n",
    "df_model_hourly = dict_ts[\"Model\"][\"Hourly\"][dt0_model:dt1_model].dropna()\n",
    "\n",
    "arr_obs = df_obs_hourly.to_numpy()\n",
    "arr_model = df_model_hourly.to_numpy()\n",
    "df_map = df_model_hourly\n",
    "\n",
    "list_model = []\n",
    "\n",
    "prange = int(100/num_percentile)\n",
    "for upb in range(prange, 100+prange, prange):\n",
    "\n",
    "  pct_obs = np.percentile(arr_obs, upb)\n",
    "  pct_model = np.percentile(arr_model, upb)\n",
    "  lowb = upb - prange\n",
    "\n",
    "  pct_model_low = np.percentile(arr_model, lowb)\n",
    "\n",
    "  dat_model = df_map[df_map.between(pct_model_low,\n",
    "                  pct_model,\n",
    "                  inclusive=\"both\")]\n",
    "  \n",
    "  ratio = pct_obs/pct_model\n",
    "  if ( np.isnan(ratio) or np.isinf(ratio)):\n",
    "    continue\n",
    "  else:\n",
    "    dat_model_new = dat_model * ratio\n",
    "    list_model.append(dat_model_new)\n",
    "\n",
    "df_tmp = pd.concat(list_model, axis = 0)\n",
    "df_tmp = df_tmp.sort_index()\n",
    "\n",
    "# check for duplicate\n",
    "dup_index = df_tmp[df_tmp.index.duplicated(keep=False)]\n",
    "if (len(dup_index) > 0):\n",
    "  print(\"Duplicate index found:\", dup_index)\n",
    "  print(\"Dropping all but first\")\n",
    "\n",
    "  df_tmp = df_tmp[~df_tmp.index.duplicated(keep='first')]\n",
    "\n",
    "# Check\n",
    "arr_model = df_tmp.to_numpy()\n",
    "for upb in range(prange, 100+prange, prange):\n",
    "\n",
    "  pct_obs = np.percentile(arr_obs, upb)\n",
    "  pct_model = np.percentile(arr_model, upb)\n",
    "\n",
    "df_hourly = df_tmp.to_frame()\n",
    "df_hourly = df_hourly.rename(columns = {df_hourly.columns[0]: col0})\n",
    "\n",
    "dict_ts_adj[\"Hourly\"] = df_hourly[col0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "trftA4P2Av4B"
   },
   "source": [
    "## Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 155
    },
    "executionInfo": {
     "elapsed": 2443,
     "status": "ok",
     "timestamp": 1609661716985,
     "user": {
      "displayName": "H K",
      "photoUrl": "",
      "userId": "12235360574546678823"
     },
     "user_tz": 480
    },
    "id": "3JD74cyMAp0D",
    "outputId": "95495f4d-059d-495d-dff2-ca29b4c18fad"
   },
   "outputs": [],
   "source": [
    "dict_ts_adj[\"Hourly_Filtered\"] = pd.DataFrame(data = None)\n",
    "print(len(dict_ts_adj[\"Hourly_Filtered\"]))\n",
    "df_hourly = dict_ts_adj[\"Hourly\"]\n",
    "\n",
    "##############################################################################\n",
    "# Remove outliers\n",
    "##############################################################################\n",
    "# Check max value\n",
    "df_nonan = df_hourly[~pd.isnull(df_hourly)]\n",
    "\n",
    "# Identify outliers\n",
    "df_remove = df_hourly[df_hourly > outlier_cut]\n",
    "\n",
    "# Extract non-NaN values\n",
    "df_remove = df_remove[~pd.isnull(df_remove)]\n",
    "\n",
    "# Extract unique values\n",
    "list_remove = df_remove.tolist()\n",
    "set_remove = set(list_remove)\n",
    "list_remove = list(set_remove)\n",
    "\n",
    "# Replace them to NaN\n",
    "if (len(list_remove) > 0):\n",
    "  print(\"Outliers:\", list_remove)\n",
    "  df_hourly = df_hourly.replace(list_remove, np.NaN)\n",
    "\n",
    "  # Check max value\n",
    "  df_nonan = df_hourly[~pd.isnull(df_hourly)]\n",
    "  print(\"Maximum after removing outliers: \" + str(max(df_nonan)))\n",
    "\n",
    "  dict_ts_adj[\"Hourly_Filtered\"] = df_hourly\n",
    "\n",
    "else:\n",
    "  pass\n",
    "\n",
    "print(len(dict_ts_adj[\"Hourly_Filtered\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2eW8V3jF_YPJ"
   },
   "source": [
    "## Print adjusted values to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NqU9lU1p_XKC"
   },
   "outputs": [],
   "source": [
    "if (icsv == 1):\n",
    "  if (len(dict_ts_adj[\"Hourly_Filtered\"]) > 0):\n",
    "    df_print = pd.DataFrame(dict_ts_adj[\"Hourly\"])\n",
    "    df_print.index.name = \"Date\"    \n",
    "    dict_ts_adj[\"Hourly\"].to_csv(os.path.join(dir_out,\n",
    "                    \"Timeseries_step2_relhum_with_outliers.csv\"),\n",
    "                    float_format = \"%.2f\", na_rep = \"NaN\",\n",
    "                    header=[\"Relative Humidity [%]\"])\n",
    "\n",
    "    df_print = pd.DataFrame(dict_ts_adj[\"Hourly_Filtered\"])\n",
    "    df_print.index.name = \"Date\"        \n",
    "    dict_ts_adj[\"Hourly_Filtered\"].to_csv(os.path.join(dir_out,\n",
    "                    \"Timeseries_step2_relhum_without_outliers.csv\"),\n",
    "                    float_format = \"%.2f\", na_rep = \"NaN\",\n",
    "                    header=[\"Relative Humidity [%]\"])\n",
    "  else:\n",
    "    df_print = pd.DataFrame(dict_ts_adj[\"Hourly\"])\n",
    "    df_print.index.name = \"Date\"\n",
    "    df_print.to_csv(os.path.join(dir_out,\n",
    "                    \"Timeseries_step2_corrected_relhum.csv\"),\n",
    "                    float_format = \"%.2f\", na_rep = \"NaN\",\n",
    "                    header=[\"Relative Humidity [%]\"])\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5xCv4JuHsLHl"
   },
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sM44GpIQR18u"
   },
   "source": [
    "## Cumulative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 6205,
     "status": "ok",
     "timestamp": 1609661720759,
     "user": {
      "displayName": "H K",
      "photoUrl": "",
      "userId": "12235360574546678823"
     },
     "user_tz": 480
    },
    "id": "7sR5mRNaIvFk",
    "outputId": "0d8d4bac-6a8a-4eed-f064-1ca901aafa63"
   },
   "outputs": [],
   "source": [
    "if (len(dict_ts_adj[\"Hourly_Filtered\"]) > 0):\n",
    "  keys = [\"Hourly\", \"Hourly_Filtered\"]\n",
    "else:\n",
    "  keys = [\"Hourly\"]\n",
    "\n",
    "for key in keys:\n",
    "  data_obs = dict_ts[\"Obs\"][\"Hourly\"][dt0_obs:dt1_obs]\n",
    "  data_model = dict_ts[\"Model\"][\"Hourly\"][dt0_model:dt1_model]\n",
    "  \n",
    "  data_adj = dict_ts_adj[key][dt0_model:dt1_model]\n",
    "\n",
    "  plt.figure(figsize = (6, 6), dpi = 200)\n",
    "\n",
    "  data = data_obs.dropna()\n",
    "  values, base = np.histogram(data, bins=num_bins)\n",
    "  cumulative = np.cumsum(values)/len(data)\n",
    "  plt.plot(base[:-1], cumulative, \"C0\")\n",
    "\n",
    "  data = data_model.dropna()\n",
    "  values, base = np.histogram(data, bins=num_bins)\n",
    "  cumulative = np.cumsum(values)/len(data)\n",
    "  plt.plot(base[:-1], cumulative, \"C1\")\n",
    "\n",
    "  data = data_adj.dropna()\n",
    "  values, base = np.histogram(data, bins=num_bins)\n",
    "  cumulative = np.cumsum(values)/len(data)\n",
    "  plt.plot(base[:-1], cumulative, \"C2\")\n",
    "\n",
    "  plt.title(\"Relative Humidity\")\n",
    "  plt.xlabel(\"Relative Humidity [%]\")\n",
    "  plt.legend([\"Observation\", \"Model (Raw)\", \"Model (Adj.)\"])\n",
    "  plt.ylim([0, 1])\n",
    "  plt.xlim([0, 100])\n",
    "  plt.grid()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Bias_Correction_Solar.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
